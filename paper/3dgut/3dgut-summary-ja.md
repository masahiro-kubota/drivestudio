# 3DGUT: 歪んだカメラと二次光線をGaussian Splattingで可能にする - 日本語サマリー

**著者**: Qi Wu¹*, Janick Martinez Esturo¹*, Ashkan Mirzaei¹,², Nicolas Moenne-Loccoz¹, Zan Gojcic¹
**所属**: ¹NVIDIA, ²University of Toronto
**URL**: https://research.nvidia.com/labs/toronto-ai/3DGUT

---

## Abstract（概要）

3D Gaussian Splatting（3DGS）は、複雑なシーンの効率的な再構成と高忠実度リアルタイムレンダリングを可能にするが、ラスタライゼーションベースの定式化により、理想的なピンホールカメラに制約され、二次照明効果のサポートがない。最近の手法ではパーティクルのトレーシングによりこれらの制限に対処しているが、レンダリング速度が大幅に低下する。

本研究では、**3D Gaussian Unscented Transform（3DGUT）**を提案し、EWAスプラッティング定式化をUnscented Transform（UT）に置き換える。UTは、パーティクルをシグマポイントを通じて近似し、任意の非線形投影下で投影でき、再投影前にオプションで変更可能である。この変更により、ローリングシャッターなどの時間依存効果を持つ歪んだカメラの自明なサポートが可能となり、同時にラスタライゼーションの効率を維持する。さらに、レンダリング定式化をトレーシングベースの手法と整合させ、同じ3D表現を通じて二次光線のトレーシングを可能にする。

---

## 1. Introduction（序論）

### 1.1 背景と課題

多視点3D再構成と新規視点合成は、コンピュータビジョンにおける古典的な問題である。近年、3D Gaussian Splatting（3DGS）によって、ボリューメトリックパーティクルベース表現が人気を集めている。3DGSは、シーンを非構造化された「ファジーな3Dガウシアンパーティクル」の集合としてモデル化し、各パーティクルは位置、スケール、回転、不透明度、外観で定義される。これらはラスタライゼーションを通じてリアルタイムで微分可能にレンダリングでき、再レンダリング損失関数を通じてすべてのパラメータを最適化できる。

しかし、3DGSのラスタライゼーションへの依存は固有の制限をもたらす：
1. **EWAスプラッティング定式化**は、ローリングシャッターなどの複雑な時間依存効果を持つ高度に歪んだカメラをサポートしない
2. **ラスタライゼーション**は、反射、屈折、影などの現象を表現するために必要な二次光線をシミュレートできない

### 1.2 研究課題

本研究は以下の2つの問いに答えることを目指す：

**Q1: なぜ3DGSは歪んだカメラとローリングシャッターの表現に不適切なのか？**

3DGSは、3Dガウシアンパーティクルをカメラ画像平面に投影するために、非線形投影関数のヤコビアンを計算する必要があるスプラッティング定式化に依存している。これは、完璧なピンホールカメラでも近似誤差を引き起こし、歪みが増加すると誤差は悪化する。さらに、EWAスプラッティング定式化内でローリングシャッターなどの時間依存効果を表現する方法が不明確である。

**解決策**: 非線形投影関数を近似する代わりに、Unscented Kalman Filter（UKF）の古典的文献からインスピレーションを得て、慎重に選択されたシグマポイントのセットを使用して3Dガウシアンパーティクルを近似する。これらのシグマポイントは、任意に複雑な投影関数を各ポイントに適用することで、カメラ画像平面に正確に投影され、その後Unscented Transform（UT）の形式でガウシアンを再推定できる。

**Q2: ラスタライゼーションのレンダリング定式化をレイトレーシングと整合させることができるか？**

レンダリング定式化の主な違いは：(i) どのパーティクルがどのピクセルに寄与するかの決定、(ii) パーティクルが交差する順序、(iii) パーティクルの評価方法である。

**解決策**: 3DGRT [34]に従い、ガウシアンパーティクル応答を3Dで評価し、同様の順序でソートする。これにより、ラスタライゼーションとレイトレーシングの両方が可能な表現が得られ、屈折や反射などの現象をレンダリングするために必要な光線を描画できる。

### 1.3 主な貢献

1. **3Dガウシアンパーティクルを近似**する（非線形投影関数ではなく）ラスタライゼーション定式化を導出。この単純な変更により、3DGSを任意のカメラモデルに拡張し、ローリングシャッターなどの複雑な時間依存効果をサポート可能
2. **3DGRTとレンダリング定式化を整合**させ、ラスタライゼーションとレイトレーシングの両方で同じ表現をレンダリング可能にし、屈折や反射などの現象をサポート

複数のデータセットで、本手法が3DGSと同等のレンダリングレートと画像忠実度を実現しながら、より高い柔軟性を提供し、歪んだカメラを持つデータセットで専用手法を上回ることを実証する。

---

## 2. Related Work（関連研究）

### 2.1 Neural Radiance Fields（NeRF）

NeRF [33]は、座標ベースニューラルネットワーク内にエンコードされた放射ボリュームとしてシーンをモデル化することで、新規視点合成の分野を変革した。元の定式化は大規模なグローバルMLPを使用していたが、後続研究では、ボクセルグリッド [27, 42, 45]、トライプレーン [3]、低ランクテンソル [4]、ハッシュテーブル [35]などの改良を導入した。

しかし、高度に最適化されたNeRF実装 [35]でも、レイマーチングの計算コストによりリアルタイム推論レートの達成に苦労している。推論を高速化するために、放射場をメッシュ [5, 53]、ハイブリッド表面-ボリューム表現 [44, 47, 49, 51]、スパースボリューム [8, 9, 38]などのより効率的な表現に変換する取り組みがあるが、これらは一般的に2段階パイプラインを伴い、トレーニング時間と複雑さが増加する。

### 2.2 Volumetric Particle Representations（ボリューメトリックパーティクル表現）

アルファ合成を介した微分可能レンダリングは、球体 [23]などのボリューメトリックパーティクルと組み合わせて探求されてきた。最近では、3D Gaussian Splatting [18]が球体をファジーな異方性3Dガウシアンに置き換えた。レイマーチングの代わりに、これらの明示的なボリューメトリックパーティクルは、高効率なラスタライゼーションを通じてレンダリングでき、品質と効率の両面で競争力のある結果を達成する。

3DGSのシンプルさと柔軟性により、多数のフォローアップ研究が生まれた：
- メモリ効率の向上 [24, 29, 31]
- 高密度化とプルーニングヒューリスティックの改善 [20, 54]
- 表面表現の強化 [10, 26, 28]
- 大規模シーンへのスケーリング [19, 26, 28]

しかし、ラスタライゼーションは非常に効率的である一方で、完璧なピンホールカメラに制限されるなどのトレードオフも導入する。従来の研究では、魚眼カメラ [25]やローリングシャッター [43]などの複雑なカメラモデルをサポートするために回避策を試みてきたが、これらの研究では各カメラタイプに専用の定式化が必要であり、カメラモデルの複雑性と歪みが増加すると品質が低下する [14]。

これに対応して、最近の研究では、ラスタライゼーションを完全に置き換え、代わりにレイトレーシングを使用して3Dガウシアンをレンダリングすることを探求している [7, 30, 34]。レイトレーシングは本質的に複雑なカメラモデルをサポートし、影、屈折、反射などの二次効果を可能にする。しかし、レンダリング効率の大幅な低下を伴い、最も最適化されたレイトレーシング手法でもラスタライゼーションより3-4倍遅い [34]。

**本研究のアプローチ**: ラスタライゼーションフレームワーク内で複雑なカメラを効率的に処理する一般化されたアプローチを提案し、計算効率を維持する。さらに、レンダリング定式化をレイトレーシングと統一し、同じ表現内でハイブリッドレンダリング技術を可能にする。

### 2.3 Unscented Transform（アンセンテッド変換）

変換を受けたランダム変数の統計を計算することは、推定と最適化の分野における基本的なタスクの1つである。変換が非線形の場合、閉形式解は存在しないため、いくつかの近似が提案されている。最も単純で広く使用されているアプローチは、1次テイラー近似を使用して非線形変換を線形化することである。しかし、局所線形性の仮定はしばしば違反され、ヤコビアン行列の導関数は自明ではなくエラーが発生しやすい。

**Unscented Transform（UT）** [16, 17]は、これらの制限に対処するために提案された。UTの重要なアイデアは、正確に変換でき、ターゲットドメインでランダム変数の統計を再推定するために使用できるシグマポイントのセットを使用してランダム変数の分布を近似することである。元々、UTはフィルタリングベースの状態推定 [16, 48]に使用されていたが、その後コンピュータビジョン [2, 15]での応用が見つかった。特に、UTは新規視点合成のコンテキスト [2]でも探求されており、その第1および第2モーメントに一致するサンプルから光線フラスタムを推定するために使用された。

---

## 3. Preliminaries（予備知識）

### 3.1 3D Gaussian Splatting表現

Kerbl et al. [18]は、応答関数 $\rho: \mathbb{R}^3 \to \mathbb{R}$ が以下のように定義される3Dガウシアンパーティクルの非順序セットを使用してシーンを表現する：

$$\rho(\boldsymbol{x}) = \exp\left(-\frac{1}{2}(\boldsymbol{x} - \boldsymbol{\mu})^T \boldsymbol{\Sigma}^{-1}(\boldsymbol{x} - \boldsymbol{\mu})\right) \quad (1)$$

ここで：
- $\boldsymbol{\mu} \in \mathbb{R}^3$：パーティクルの位置
- $\boldsymbol{\Sigma} \in \mathbb{R}^{3 \times 3}$：共分散行列

勾配ベースの最適化中に $\boldsymbol{\Sigma}$ が正半定値であることを保証するため、以下のように回転行列 $\boldsymbol{R} \in \text{SO}(3)$ とスケーリング行列 $\boldsymbol{S} \in \mathbb{R}^{3 \times 3}$ に分解される：

$$\boldsymbol{\Sigma} = \boldsymbol{RSS}^T\boldsymbol{R}^T \quad (2)$$

実際には、$\boldsymbol{R}$ と $\boldsymbol{S}$ の両方がベクトルとして保存される（回転には四元数 $\in \mathbb{R}^4$、スケーリングには $\in \mathbb{R}^3$）。各パーティクルには、不透明度係数 $\sigma \in \mathbb{R}$ と、視点依存のパラメトリック放射関数 $c(\boldsymbol{d}): \mathbb{R}^3 \to \mathbb{R}^3$ も関連付けられる（実際には次数 $n = 3$ の球面調和関数で表現）。

### 3.2 パーティクル応答の決定

3DGSラスタライゼーションフレームワーク内では、3Dパーティクルを個々のピクセルへの寄与を決定するためにカメラ画像平面に投影する必要がある。このため、3DGSは [57]に従い、1次近似を介して画像座標での投影ガウシアンの共分散行列 $\boldsymbol{\Sigma}' \in \mathbb{R}^{2 \times 2}$ を計算する：

$$\boldsymbol{\Sigma}' = \boldsymbol{J}_{[2:3]} \boldsymbol{W} \boldsymbol{\Sigma} \boldsymbol{W}^T \boldsymbol{J}^T_{[2:3]} \quad (3)$$

ここで：
- $\boldsymbol{W} \in \text{SE}(3)$：パーティクルをワールド座標系からカメラ座標系に変換
- $\boldsymbol{J} \in \mathbb{R}^{3 \times 3}$：射影変換のアフィン近似のヤコビアン行列（テイラー展開の線形項から取得）

画像平面上の投影 $\boldsymbol{v}_x \in \mathbb{R}^2$ から、与えられたピクセル $\mathbb{R}^3$ に対するパーティクル $i$ のガウシアン応答を2Dで計算できる：

$$\rho_i(\boldsymbol{x}) = \exp\left(-\frac{1}{2}(\boldsymbol{v}_x - \boldsymbol{v}_{\mu})^T \boldsymbol{\Sigma}'^{-1}(\boldsymbol{v}_x - \boldsymbol{v}_{\mu})\right) \quad (4)$$

ここで $\boldsymbol{v}_{\mu} \in \mathbb{R}^2$ はパーティクルの投影平均を示す。

### 3.3 Volumetric Particle Rendering（ボリューメトリックパーティクルレンダリング）

原点 $\boldsymbol{o} \in \mathbb{R}^3$ と方向 $\boldsymbol{d} \in \mathbb{R}^3$ を持つカメラ光線 $\boldsymbol{r}(\tau) = \boldsymbol{o} + \tau \boldsymbol{d}$ の色 $\boldsymbol{c} \in \mathbb{R}^3$ は、数値積分を使用して上記のボリューメトリックパーティクル表現からレンダリングできる：

$$c(\boldsymbol{o}, \boldsymbol{d}) = \sum_{i=1}^{N} \boldsymbol{c}_i(\boldsymbol{d}) \alpha_i \prod_{j=1}^{i-1} (1 - \alpha_j) \quad (5)$$

ここで：
- $N$：与えられた光線に寄与するパーティクルの数
- 不透明度 $\alpha_i \in \mathbb{R}$ は、任意の $\tau \in \mathbb{R}^+$ に対して $\alpha_i = \sigma_i \rho_i(\boldsymbol{o} + \tau \boldsymbol{d})$ と定義される

---

## 4. Method（手法）

### 目的

本手法の目的は、3DGS [18]および3DGRT [34]を拡張し、以下を実現する定式化を開発すること：

1. 高度に歪んだカメラおよびローリングシャッターなどの時間依存カメラ効果に対応
2. スプラッティングまたはトレーシングのいずれかで同じ再構成をレンダリングできるようにレンダリング定式化を統一し、トレースされた二次光線によるハイブリッドレンダリングを可能にする

これらすべてを、ラスタライゼーションの効率を維持しながら実現する。

### 4.1 Unscented Transform（アンセンテッド変換）

図2に示すように、3DGSで3Dガウシアンパーティクルをカメラ画像平面に投影するために使用されるEWAスプラッティング定式化は、射影変換のアフィン近似の線形化に依存している（式3）。しかし、このアプローチにはいくつかの顕著な制限がある：

1. **テイラー展開の高次項を無視**するため、完璧なピンホールカメラでも投影誤差が発生し [14]、カメラの歪みで誤差が増加する
2. **各カメラモデルに特定のヤコビアンを導出する必要がある**（例：[25]の等距離魚眼モデル）ため、煩雑でエラーが発生しやすい
3. **投影を単一の関数として表現する必要がある**ため、ローリングシャッターなどの時間依存効果を考慮する際に特に困難

これらの制限を克服するため、Unscented Transform（UT）のアイデアを活用し、代わりに**対称N次元ガウシアンパーティクルを $2N + 1$ のシグマポイントを使用して近似**することを提案する。これらのシグマポイントは、目標分布の少なくとも最初の3つのモーメントを正確に変換できる。

#### シグマポイントの定義

セクション3で説明した3Dガウシアンシーン表現を考慮すると、パーティクルは位置 $\boldsymbol{\mu}$ と共分散行列 $\boldsymbol{\Sigma}$ によって特徴付けられ、シグマポイント $\mathcal{X} = \{\boldsymbol{x}_i\}_{i=0}^6$ は以下のように定義される：

$$\boldsymbol{x}_i = \begin{cases}
\boldsymbol{\mu} & \text{for } i = 0 \\
\boldsymbol{\mu} + \sqrt{(3 + \lambda)\boldsymbol{\Sigma}_{[i]}} & \text{for } i = 1, 2, 3 \quad (6) \\
\boldsymbol{\mu} - \sqrt{(3 + \lambda)\boldsymbol{\Sigma}_{[i-3]}} & \text{for } i = 4, 5, 6
\end{cases}$$

式(2)の共分散の利用可能な因数分解を使用して行列平方根を読み取る。

#### 重みの定義

対応する重み $\mathcal{W} = \{w_i\}_{i=0}^6$ は以下のように与えられる：

**平均の重み**:
$$w_i^{\mu} = \begin{cases}
\frac{\lambda}{3 + \lambda} & \text{for } i = 0 \\
\frac{1}{2(3 + \lambda)} & \text{for } i = 1, \ldots, 6
\end{cases} \quad (7)$$

**共分散の重み**:
$$w_i^{\Sigma} = \begin{cases}
\frac{\lambda}{3 + \lambda} + (1 - \alpha^2 + \beta) & \text{for } i = 0 \\
\frac{1}{2(3 + \lambda)} & \text{for } i = 1, \ldots, 6
\end{cases} \quad (8)$$

ここで：
- $\lambda = \alpha^2(3 + \kappa) - 3$
- $\alpha$：平均周りのシグマポイントの広がりを制御するハイパーパラメータ
- $\kappa$：通常0に設定されるスケーリングパラメータ
- $\beta$：分布に関する事前知識を組み込むために使用 [48]

#### 投影と再推定

各シグマポイントは、非線形投影関数 $\boldsymbol{v}_{x_i} = g(\boldsymbol{x}_i)$ を使用してカメラ画像平面に独立して投影できる。2D円錐は、その後、ガウシアンの重み付けされた事後サンプル平均および共分散行列として近似できる：

**2D平均**:
$$\boldsymbol{v}_{\mu} = \sum_{i=0}^{6} w_i^{\mu} \boldsymbol{v}_{x_i} \quad (9)$$

**2D共分散**:
$$\boldsymbol{\Sigma}' = \sum_{i=0}^{6} w_i^{\Sigma} (\boldsymbol{v}_{x_i} - \boldsymbol{v}_{\mu})(\boldsymbol{v}_{x_i} - \boldsymbol{v}_{\mu})^T \quad (10)$$

2D円錐が計算されると、[18, 37]で提案されたのと同じタイリングおよびカリング手順を適用して、どのパーティクルがどのピクセルに影響するかを決定できる。次のセクションで説明するように、本手法のパーティクル応答評価は2D円錐に依存しない。代わりに、UTは各ピクセルに寄与するパーティクルを効率的に決定するための加速構造としてのみ機能し、非線形投影関数を通じた後方パスの計算を回避する必要性を排除する。

### 4.2 Evaluating Particle Response（パーティクル応答の評価）

各ピクセルに寄与するガウシアンパーティクルが識別されたら、その応答をどのように評価するかを決定する必要がある。3DGRT [34]に従い、与えられた光線に沿った最大パーティクル応答のポイントに位置する単一サンプルを使用して、パーティクルを直接3Dで評価する。

3DGSの2D円錐応答評価方法と本手法の3D応答評価方法の比較を図3に示す。具体的には、光線 $\boldsymbol{r}(\tau)$ に沿ってパーティクル応答を最大化する距離 $\tau_{\text{max}} = \arg\max_{\tau} \rho(\boldsymbol{o} + \tau \boldsymbol{d})$ を以下のように計算する：

$$\tau_{\text{max}} = \frac{(\boldsymbol{\mu} - \boldsymbol{o})^T \boldsymbol{\Sigma}^{-1} \boldsymbol{d}}{\boldsymbol{d}^T \boldsymbol{\Sigma}^{-1} \boldsymbol{d}} = \frac{-\boldsymbol{o}_g^T \boldsymbol{d}_g}{\boldsymbol{d}_g^T \boldsymbol{d}_g} \quad (11)$$

ここで：
- $\boldsymbol{o}_g = \boldsymbol{S}^{-1} \boldsymbol{R}^T(\boldsymbol{o} - \boldsymbol{\mu})$：ガウシアン正準空間での光線原点
- $\boldsymbol{d}_g = \boldsymbol{S}^{-1} \boldsymbol{R}^T \boldsymbol{d}$：ガウシアン正準空間での光線方向

2Dでパーティクル評価を実行する3DGSとは異なり、本アプローチは投影関数を通じた勾配の伝播を回避し、近似を避け、潜在的な数値不安定性を軽減する。スペースの制限により、数値的に安定した後方パスの導出は補足資料セクションBに記載されている。

### 4.3 Sorting Particles（パーティクルのソート）

提案されたボリューメトリックレンダリング定式化、すなわちレンダリング方程式（式5）とパーティクル評価（式11）の両方は、3DGRTで使用されるものと同等である。しかし、3DGRTは専用の加速構造 [36]により光線に沿った正確な $\tau_{\text{max}}$ 順序でヒットパーティクルを収集できるが、3DGSは各タイルに対してグローバルにソートする。

より良い近似を得るために、**Multi-layers Alpha Blending（MLAB）** [41]（しばしば [37]で示される）を使用することを提案する。これは、光線ごとの $k$-最遠ヒットパーティクル（通常 $k = 16$）をバッファに格納する。バッファに格納できない最も近いヒットは、ブレンドされた部分の透過率が消失するまで段階的にアルファブレンドされる。

代替として、**Hybrid Transparency（HT）**ブレンディング戦略 [32]が最近ガウシアンパーティクルのスプラッティングに使用されている [13]。$k$-最遠ヒットパーティクルを格納し、最も近いヒットを段階的にブレンドする代わりに、$k$最も近いものを格納し、最も遠いヒットを段階的にブレンドする。これにより、正確な $k$-最近接ヒットパーティクルを回復できるが、すべてのパーティクルを通過する必要があり、専用の最適化とヒューリスティックがないと非常に遅くなる可能性がある。

### 4.4 Implementation and Training（実装とトレーニング）

[18, 34]の研究に基づき、PyTorchで手法を実装し、計算集約的な部分にはカスタムCUDAカーネルを使用した。さらに、Radl et al. [37]が提案する高度なカリング戦略を採用している。

**ハイパーパラメータ設定**:
- UT: $\alpha = 1.0$, $\beta = 2.0$, $\kappa = 0.0$（すべての評価で）
- 2Dスクリーン空間勾配にアクセスできないため、[34]に従い、3D位置勾配をカメラまでの距離の半分で割ったもので置き換え、300イテレーションごとに蓄積とプルーニングを保証

**損失関数**:
30kイテレーションでモデルをトレーニングし、L2損失 $\mathcal{L}_2$ と知覚損失 $\mathcal{L}_{\text{SSIM}}$ の重み付け合計を使用：

$$\mathcal{L} = \mathcal{L}_2 + 0.2\mathcal{L}_{\text{SSIM}}$$

---

## 5. Experiments and Ablations（実験とアブレーション）

### 5.1 評価設定

**モデルバリアント**:
- **Ours**: UT定式化（Sec. 4.1）と3Dでのパーティクル評価（Sec. 4.2）のみで3DGS [18]を拡張したバージョン
- **Ours (sorted)**: Sec. 4.3で詳述された光線ごとのソート戦略を追加し、3DGRT [34]との統一につながるバージョン

**評価指標**:
- **品質**: PSNR（ピーク信号対雑音比）、LPIPS（学習知覚画像パッチ類似度）、SSIM（構造的類似度）
- **速度**: 単一画像のレンダリングに必要な時間、FPS（フレーム/秒）
- **ハードウェア**: NVIDIA RTX 6000 Ada GPU

**ベースライン**:
- **スプラッティング手法**: 3DGS [18]、StopThePop [37]
- **レイトレーシング手法**: 3DGRT [34]、EVER [30]
- **魚眼カメラ専用**: FisheyeGS [25]
- **NeRFベース**: ZipNeRF [2]

### 5.2 MipNeRF360データセット

**データセット**: 9つの大規模屋外および屋内シーンからなる最も人気のある新規視点合成ベンチマーク [1]。屋外シーンは4倍、屋内シーンは2倍のダウンサンプリング画像を使用。

**結果（表1）**:
- **品質**: 完璧なピンホール入力を持つこのデータセットで、**Ours**と**Ours (sorted)**は、すべてのスプラッティングおよびトレーシング手法と同等の知覚品質を達成
- **速度**: 本手法は3DGS [18]と同等のフレームレートを達成（**265+ FPS**）。最も近い競合である3DGRT [34]は52FPSのみ
- **詳細比較**: 図4に定性的比較を示す

**詳細タイミング（表2）**:
- **Ours vs 3DGS**: 前処理が若干遅い（1.34ms vs 0.59ms）が、レンダリング全体では許容範囲内（3.77ms vs 2.88ms）
- **Ours (sorted) vs 3DGRT**: 大幅に高速（4.98ms vs 19.24ms）

### 5.3 Tanks & Templesデータセット

**データセット**: 照明変動を含む2つの大規模屋外シーン（*Tank*と*Train*）[21]。*Truck*シーンには一時的なオブジェクトも含まれる。

**結果（表1）**:
- 3DGSと同等の品質を維持しながら、高いレンダリング速度を実現（**272-277 FPS**）
- 定性的比較は補足資料に記載

### 5.4 Scannet++（魚眼カメラ）

**データセット**: 魚眼カメラで1752×1168ピクセルの解像度でキャプチャされた大規模屋内データセット [55]。FisheyeGS [25]と同じ6シーンを使用。

**比較対象**:
- **3DGS**: 画像をアンディストーションしてトレーニングし、FisheyeGS定式化を使用してレンダリング（画像の大部分が失われるため不利）
- **FisheyeGS [25]**: この特定のカメラモデル用にヤコビアンを導出した専用手法

**結果（表3）**:
- **Ours (sorted)**: すべての知覚指標でFisheyeGSを大幅に上回る
  - PSNR: 29.11（FisheyeGS: 28.15）
  - SSIM: 0.910（FisheyeGS: 0.901）
  - LPIPS: 0.252（FisheyeGS: 0.261）
- **ガウシアン数**: 半分以下（0.38M vs 1.07M）
- **柔軟性**: FisheyeGSは特定のカメラモデル用にヤコビアンを導出する必要があるが、本手法は任意のカメラモデルに自明に適用可能
- 定性的結果を図5に示す

### 5.5 Waymo（自動運転データセット）

**データセット**: ローリングシャッターを持つ歪んだカメラでキャプチャされた大規模自動運転データセット [46]。3DGRT [34]に従い、正確な再構成を可能にするために動的オブジェクトのない9シーンを選択。

**特殊な損失関数**:
Waymoデータセットでは、LiDAR深度と画像不透明度に対する追加の損失を組み込み：

$$\mathcal{L}^{\text{waymo}} = \mathcal{L} + 1.0 \lambda_1^{\text{depth}} + 0.01\lambda_2^{\text{opacity}}$$

**初期化**: カメラデータと組み合わせたスクリーン投影LiDARポイントから生成された色付き点群を使用。

**結果（表5、補足資料）**:
- **Ours (sorted)**: 3DGRTより優れた品質を達成
  - PSNR: 30.16（3DGRT: 29.99）
  - SSIM: 0.900（3DGRT: 0.897）
- **3DGS**: ローリングシャッター効果なしで補正された画像でトレーニングおよび評価する必要があるため、直接比較不可
- 定性的可視化は図6および図15に示す

### 5.6 投影品質の分析（補足資料）

**評価方法**: モンテカルロ（MC）サンプリング（500サンプル/参照）を基準として、EWAとUT基づく投影のKullback-Leibler（KL）ダイバージェンスを評価。低いKL値は、より良い近似を示す。

**結果（図14）**:
1. **静的ピンホールカメラ**: 両方の分布が一致
2. **静的魚眼カメラ**: UTベースの投影がEWAベースの推定よりも正確（投影の非線形性が高い場合にUTがより良い近似を提供）
3. **ローリングシャッター（RS）カメラポーズ**:
   - RS対応UTベースの投影は依然としてRS対応MC参照をよく近似
   - RS非対応EWA線形化は破綻し、この場合を近似できない（EWAベースのRSレンダリングで観察される引き裂きアーティファクトは、これらの不正確な投影によって発生）

**歪みの影響（図12、13）**:
- **等距離魚眼カメラ**: 本アプローチは、EWA用のカスタム導出ヤコビアンよりも正確な近似を提供
- **放射歪みとRS**: EWAには[18]のヤコビアンを使用（これらの追加歪みを考慮せず）。本手法は、歪みパラメータに関係なく、ほぼ同じ低KLダイバージェンスを維持

---

## 6. Applications（応用）

3DGUTは、ラスタライゼーションフレームワーク内のパーティクルシーン表現では以前達成不可能だった新しいアプリケーションと技術を可能にする。

### 6.1 Complex Cameras（複雑なカメラ）

**歪んだカメラモデル**:
UTを使用したパーティクルの投影により、3DGUTは歪んだカメラでトレーニングできるだけでなく、完璧なピンホールカメラ入力を使用してトレーニングされたシーンで、さまざまな歪みを持つ異なるカメラモデルをレンダリングすることも可能（図9上段）。

**ローリングシャッター**:
歪んだカメラのモデリングに加えて、3DGUTはカメラモーションを投影定式化に忠実に組み込むことができ、自動運転とロボット工学の分野で一般的に遭遇するローリングシャッターなどの時間依存カメラ効果のサポートを提供する。光学歪みは画像補正で対処できるが、投影関数の時間依存性を線形化フレームワークに組み込むことは非常に自明ではない。

ローリングシャッターがさまざまな再構成手法に与える影響を示すために、図7では、カメラのモーションとシャッター時間が提供されるMoenne-Loccoz et al. [34]が提供する合成データセットを使用している。

### 6.2 Secondary Rays and Lighting Effects（二次光線と照明効果）

**3DGRT [34]との表現の整合**:
3DGSと3DGRTのレンダリング定式化は、主に以下の点で異なる：(i) どのパーティクルがどのピクセルに寄与するかの決定、(ii) パーティクル評価の順序、(iii) パーティクル応答の計算。Secs. 4.2と4.3では、これらの違いを減らして、ラスタライズとトレースの両方が可能な共通の3D表現に到達することを目指した。

図8は、異なる手法でトレーニングされ、3DGRT [34]で評価された3D表現の比較を示す。しかし、いくつかの不一致が残る。全体として、**Ours (sorted)**はStopThePopや3DGSよりも3DGRTとはるかに良い整合を達成する。

**二次光線**:
レンダリング定式化を3DGRT [34]に整合させることで、同じ表現内で一次光線をラスタライズし、二次光線をトレースすることにより、ハイブリッドレンダリングが可能になる。具体的には：

1. シーンとのすべての一次光線交差を計算
2. ラスタライゼーションを使用してこれらの一次光線をレンダリング
3. 光線の最も近い交差の背後にあるすべてのガウシアンを破棄
4. 3DGRTを使用して二次光線を計算およびトレース

このハイブリッドレンダリング手法により、反射や屈折などの複雑な視覚効果を実現でき、これらはレイトレーシングでのみ可能であった。

---

## 7. Discussion（考察）

### 7.1 まとめ

3DGS [18]の非線形投影関数の線形化をUnscented Transformに置き換えるというシンプルなアイデアを提案した。この変更により、以下が可能になる：

1. **3DGSを歪んだカメラにシームレスに一般化**
2. **ローリングシャッターなどの時間依存効果をサポート**
3. **3DGRT [34]とレンダリング定式化を整合**させ、ハイブリッドレンダリングを実行し、照明効果のための二次光線をアンロック

### 7.2 Limitations and Future Work（制限と今後の研究）

**制限**:

1. **速度**: レイトレーシングベースの手法 [7, 30, 34]よりも大幅に効率的だが、[18]よりもわずかに遅い（表2参照）
   - UT評価と3Dパーティクル評価の追加複雑性がレンダリング時間に影響

2. **大きな歪みでの2D形状の劣化**: UTは任意の歪み下でシグマポイントの正確な投影を許可するが、結果として投影される形状は大きな歪みの場合に2Dガウシアンから逸脱する
   - これにより、どのパーティクルがどのピクセルに寄与するかの近似が低下

3. **重複ガウシアンのレンダリング**: 本手法は依然として単一ポイントを使用して各プリミティブを評価してソートするため、重複するガウシアンを正確にレンダリングできない
   - EVER [30]などのアプローチがこの制限に対処するための有望な方向性を提供

**今後の研究の方向性**:

1. **自動運転とロボット工学**: 歪んだカメラでのトレーニングとレンダリングが不可欠な分野での新しい研究を促進
2. **逆レンダリングとリライティング**: 3DGRT [34]との整合により、これらの領域での今後の研究に興味深い機会を開く
3. **最適化の改善**: レンダリング速度をさらに向上させるための専用最適化
4. **より高度なソート戦略**: 重複ガウシアンの正確なレンダリングのための改良

### 7.3 インパクト

本研究は、以下の点で重要な貢献をする：

1. **汎用性**: 任意のカメラモデルに対して単一の定式化を提供し、カメラモデルごとにヤコビアンを導出する必要性を排除
2. **効率と品質のバランス**: ラスタライゼーションの効率を維持しながら、レイトレーシングの柔軟性を提供
3. **ハイブリッドレンダリング**: 一次光線のラスタライゼーションと二次光線のトレーシングを組み合わせ、複雑な照明効果を可能にする
4. **実世界のアプリケーション**: 自動運転、ロボット工学、VR/ARなどの分野での実用的な応用を可能にする

---

## 8. Technical Details（技術的詳細）

### 8.1 一般化ガウシアンパーティクル（補足資料A）

3DGRT [34]では、異なるカーネル関数を持つパーティクルが提案されている。本アプローチも異なるパーティクルをサポートする。次数 $n$ の一般化ガウシアンカーネル関数を以下のように定義：

$$\rho(\boldsymbol{x}) = \exp\left(-\lambda\left((\boldsymbol{x} - \boldsymbol{\mu})^T \boldsymbol{\Sigma}^{-1}(\boldsymbol{x} - \boldsymbol{\mu})\right)^{\frac{r}{2}}\right) \quad (12)$$

ここで $\lambda = \frac{r}{2r}$ は、参照ガウシアンカーネルとして与えられた距離 $r$ で同じカーネル応答を得るために定義されたスケール因子（$r = 3$ を使用）。

**注**: 3DGRTの「次数2の一般化ガウシアン」は、本手法の「次数4の一般化ガウシアンカーネル」に対応。

**品質と速度のトレードオフ（表4）**:
- 次数2（ガウシアン）: PSNR 28.77、207 FPS
- 次数4（3DGRT）: PSNR 28.46、233 FPS
- より高次のカーネルは速度が速いが、品質がわずかに低下

### 8.2 数値的に安定した後方パス（補足資料B）

ガウシアン正準空間での $\tau_{\text{max}}$ を以下のように定義：

$$\tau_{\text{max}_g} = -\boldsymbol{o}_g \frac{\boldsymbol{d}_g}{||\boldsymbol{d}_g||} \quad (13)$$

ここで：
- $\boldsymbol{o}_g = \boldsymbol{S}^{-1}\boldsymbol{R}^T(\boldsymbol{o} - \boldsymbol{\mu})$
- $\boldsymbol{d}_g = \boldsymbol{S}^{-1}\boldsymbol{R}^T \boldsymbol{d}$

$\omega_g^2 = ||\boldsymbol{o}_g + \tau_{\text{max}_g} \frac{\boldsymbol{d}_g}{||\boldsymbol{d}_g||}||^2$ をガウシアンパーティクル中心から最大応答ポイントまでの2乗距離とすると、$\alpha = \sigma e^{-0.5\omega_g^2}$。

偏微分は以下のように計算できる：

$$\frac{\partial \alpha}{\partial \omega_g^2} = -0.5\sigma e^{-0.5\omega_g^2} \quad (14)$$

$$\frac{\partial \omega_g^2}{\partial \boldsymbol{o}_g} = 2\boldsymbol{o}_g + 2\tau_{\text{max}_g T} \frac{\boldsymbol{d}_g}{||\boldsymbol{d}_g||} \quad (15)$$

$$\frac{\partial \boldsymbol{o}_g}{\partial \boldsymbol{\mu}} = -\boldsymbol{S}^{-1}\boldsymbol{R}^T \quad (16)$$

### 8.3 ガウシアンラスタライゼーションアルゴリズム（補足資料E）

**アルゴリズム1: RASTERIZE**
- **入力**: ガウシアンパラメータ $\{\boldsymbol{\mu}_i, \boldsymbol{R}_i, \boldsymbol{S}_i, \sigma_i\}_{i=1}^N$、カメラ外部パラメータ $\boldsymbol{W}$、カメラ内部パラメータ $\boldsymbol{D}$
- **出力**: 2D AABB $\boldsymbol{r}_i$
- **ステップ**:
  1. 各パーティクルに対して反復
  2. 2Dガウシアンを推定（ESTIMATE2DGAUSSIAN）
  3. 不透明度を使用してより厳密な2D範囲を計算
  4. タイルベースラスタライゼーション用の2D矩形を計算

**アルゴリズム2: ESTIMATE2DGAUSSIAN**
- **入力**: ガウシアンパラメータ $\boldsymbol{\mu}, \boldsymbol{R}, \boldsymbol{S}$、カメラパラメータ $\boldsymbol{W}, \boldsymbol{D}$、ハイパーパラメータ $\alpha, \beta, \kappa$
- **出力**: 2D平均 $\boldsymbol{v}_{\mu}$、2D共分散 $\boldsymbol{\Sigma}'$
- **ステップ**:
  1. $\lambda$ を計算
  2. シグマポイントをサンプリング（式6）
  3. 重みを計算（式7、8）
  4. ポイントを投影（$g(x)$ を評価）
  5. 平均を推定（式9）
  6. 共分散を推定（式10）

---

## 9. Experimental Results Summary（実験結果のまとめ）

### 9.1 定量的結果

**MipNeRF360 + Tanks & Temples（表1）**:
| 手法 | 複雑なカメラ | ポッピングなし | PSNR↑ | SSIM↑ | LPIPS↓ | FPS↑ |
|------|--------------|----------------|-------|-------|--------|------|
| 3DGS | ✗ | ✗ | 27.26 | 0.803 | 0.240 | 347 |
| Ours | ✓ | ✗ | 27.26 | 0.810 | 0.218 | 265 |
| 3DGRT | ✓ | ✓ | 27.20 | 0.818 | 0.248 | 52 |
| Ours (sorted) | ✓ | ✓ | 27.26 | 0.812 | 0.215 | 200 |

**Scannet++魚眼データセット（表3）**:
| 手法 | PSNR↑ | SSIM↑ | LPIPS↓ | ガウシアン数↓ |
|------|-------|-------|--------|---------------|
| FisheyeGS | 28.15 | 0.901 | 0.261 | 1.07M |
| Ours (sorted) | 29.11 | 0.910 | 0.252 | 0.38M |

**Waymo自動運転データセット（表5）**:
| 手法 | PSNR↑ | SSIM↑ |
|------|-------|-------|
| 3DGS | 29.83 | 0.917 |
| 3DGRT | 29.99 | 0.897 |
| Ours (sorted) | 30.16 | 0.900 |

### 9.2 主な観察

1. **ピンホールカメラでの性能**: 3DGSと同等の品質を維持しながら、5倍以上の速度で複雑なカメラをサポート（265 FPS vs 3DGRTの52 FPS）

2. **魚眼カメラでの優位性**: 専用手法（FisheyeGS）を大幅に上回り、半分以下のガウシアン数で実現

3. **ローリングシャッター対応**: 自動運転データセットで最高の品質を達成

4. **効率**: レイトレーシング手法より3-4倍高速で、ラスタライゼーション手法に近い速度を維持

---

## 10. Conclusion（結論）

3DGUT（3D Gaussian Unscented Transform）は、3D Gaussian Splattingの重要な制限を克服する画期的な手法である。**Unscented Transform**を活用することで、非線形投影関数を線形化する代わりに3Dガウシアンパーティクル自体を近似し、以下を実現する：

### 主な成果

1. **汎用カメラサポート**: 任意のカメラモデル（ピンホール、魚眼、放射歪み等）に対して単一の定式化を提供
2. **時間依存効果**: ローリングシャッターなどの複雑な効果を自然にサポート
3. **ハイブリッドレンダリング**: ラスタライゼーションとレイトレーシングを統一し、二次照明効果を可能に
4. **高効率**: レイトレーシング手法より大幅に高速で、ラスタライゼーションの効率をほぼ維持
5. **高品質**: 従来手法と同等以上の視覚品質を達成

### 技術的革新

- **数学的エレガンス**: UTの使用により、ヤコビアンの導出が不要で、勾配が正確かつ無償
- **3D評価**: パーティクル応答を3Dで直接評価し、投影関数を通じた勾配伝播を回避
- **効率的なソート**: MLABを使用した光線ごとのソートで、より正確なレンダリングを実現

### 実用的インパクト

本研究は、自動運転、ロボット工学、VR/AR、映画制作など、歪んだカメラや複雑な照明効果が重要な多くの実世界アプリケーションへの道を開く。特に、専用の定式化なしで任意のカメラモデルをサポートする能力は、3D再構成技術の民主化に大きく貢献する。

---

**ソースコード**: https://github.com/nv-tlabs/3dgut
